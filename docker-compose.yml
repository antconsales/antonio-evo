version: "3.8"

# Antonio Evo - Service Orchestration
# Optimized for Acemagician Mini PC (AMD Ryzen 5 5600U, 32GB RAM)
#
# Usage:
#   docker-compose up -d          # Start all services
#   docker-compose logs -f        # View logs
#   docker-compose down           # Stop all services
#
# Ollama: Install natively for best performance
#   curl -fsSL https://ollama.com/install.sh | sh
#   ollama pull mistral

services:
  # ============================================
  # ASR - faster-whisper HTTP Server
  # Using 'small' model - 32GB RAM allows better models
  # ============================================
  faster-whisper:
    image: fedirz/faster-whisper-server:latest-cpu
    container_name: antonio-asr
    ports:
      - "8803:8000"
    environment:
      - WHISPER__MODEL=small
      - WHISPER__DEVICE=cpu
      - WHISPER__COMPUTE_TYPE=int8
    volumes:
      - ./models/whisper:/root/.cache/huggingface
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s
    deploy:
      resources:
        limits:
          memory: 3G
        reservations:
          memory: 1G

  # ============================================
  # TTS - Piper HTTP Server
  # ============================================
  piper-http:
    image: rhasspy/wyoming-piper:latest
    container_name: antonio-tts
    ports:
      - "8804:10200"
    volumes:
      - ./models/piper:/data
    command: --voice it_IT-riccardo-x_low
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "10200"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # ============================================
  # Vector Database - Qdrant
  # More memory for larger knowledge bases
  # ============================================
  qdrant:
    image: qdrant/qdrant:latest
    container_name: antonio-qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./data/qdrant:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/readyz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 512M

  # ============================================
  # OPTIONAL: Ollama in Docker
  # Uncomment if you prefer Docker over native
  # ============================================
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: antonio-ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ./models/ollama:/root/.ollama
  #   environment:
  #     - OLLAMA_KEEP_ALIVE=10m
  #     - OLLAMA_NUM_PARALLEL=2
  #   restart: unless-stopped
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 16G
  #       reservations:
  #         memory: 8G

# ============================================
# Volumes for persistence
# ============================================
volumes:
  whisper-models:
    driver: local
  piper-voices:
    driver: local
  qdrant-storage:
    driver: local

# ============================================
# Network configuration
# ============================================
networks:
  default:
    name: antonio-network
    driver: bridge
